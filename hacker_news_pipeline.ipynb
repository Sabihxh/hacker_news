{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 keywords of latest Hacker News posts\n",
    "\n",
    "    1. Gets data from latest 1000 posts on Hacker news with atleast 51 points and 2 comments.\n",
    "    2. Removes any posts that start with 'Ask Hn'.\n",
    "    3. Creates non case-sensitive keyword dictionary with stop words and punctuations.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import io\n",
    "import json\n",
    "from stop_words import stop_words\n",
    "import string\n",
    "\n",
    "from pipeline import Pipeline\n",
    "from pipeline import build_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task()\n",
    "def get_raw_data():\n",
    "    \"\"\"\n",
    "    Returns list of dicts where each dict contains story data from hackernews.\n",
    "    Loops through url for maximum 50 times or until nbPages from request result is 0.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    url = 'http://hn.algolia.com/api/v1/search_by_date?tags=story&numericFilters=points>50,num_comments>1&maxFacetHits=100&hitsPerPage=100&page={}'\n",
    "    for page in range(50):\n",
    "        page_url = url.format(page)\n",
    "        response = requests.get(page_url)\n",
    "        data = response.json()\n",
    "        if data['nbPages'] == 0:\n",
    "            break\n",
    "        result += data.get('hits', [])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on=get_raw_data)\n",
    "def filter_stories(data):\n",
    "    for row in data:\n",
    "        if not row['title'].startswith('Ask HN'):\n",
    "            yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on=filter_stories)\n",
    "def json_to_csv(data):\n",
    "    header = ['objectID', 'created_at', 'url', 'points', 'title']\n",
    "    lines = []\n",
    "    for row in data:\n",
    "        lines.append(\n",
    "            (\n",
    "            row['objectID'],\n",
    "            datetime.strptime(row['created_at'][:10], '%Y-%m-%d'),\n",
    "            row['url'],\n",
    "            row['points'],\n",
    "            row['title'],\n",
    "            )\n",
    "        )\n",
    "    return build_csv(\n",
    "        lines,\n",
    "        header=header,\n",
    "        file=io.StringIO()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on=json_to_csv)\n",
    "def extract_titles(file_obj):\n",
    "    for row in csv.reader(file_obj):\n",
    "        yield row[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on=extract_titles)\n",
    "def clean_titles(titles):\n",
    "    \"\"\"\n",
    "    Generator of titles (lowercased and punctuations removed)\n",
    "    \"\"\"\n",
    "    for title in titles:\n",
    "        for char in string.punctuation:\n",
    "            title = title.replace(char, '')\n",
    "        yield title.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on=clean_titles)\n",
    "def build_keyword_dictionary(titles):\n",
    "    \"\"\"\n",
    "    Returns keyword dictionary excluding stop words\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for title in titles:\n",
    "        words = title.split(' ')\n",
    "        for word in words:\n",
    "            if not word or word in stop_words:\n",
    "                continue\n",
    "            if word not in result:\n",
    "                result[word] = 0\n",
    "            result[word] += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on=build_keyword_dictionary)\n",
    "def sort_keywords(keyword_dict):\n",
    "    \"\"\"\n",
    "    Returns list of tuples sorted by frequency\n",
    "    \"\"\"\n",
    "    popular_words = sorted(keyword_dict, key=lambda x: keyword_dict[x], reverse=True)[:10]\n",
    "    return [(x, keyword_dict[x]) for x in popular_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    result = pipeline.run()\n",
    "    keywords_dict = result[list(result.keys())[-1]]\n",
    "    print('Top keywords of latest Hacker News posts:\\n')\n",
    "    for word, freq in keywords_dict:\n",
    "        print('{}: {}'.format(word, freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top keywords of latest Hacker News posts:\n",
      "\n",
      "new: 27\n",
      "google: 27\n",
      "pdf: 25\n",
      "data: 23\n",
      "programming: 21\n",
      "2018: 19\n",
      "use: 16\n",
      "facebook: 15\n",
      "amazon: 15\n",
      "2017: 15\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
